{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c17c6eb-990b-4586-b862-bf758eae4474",
   "metadata": {},
   "source": [
    "# Property value Prediction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook documents the process of creating randomforest regression models to the value of various property types New York City based on the properties proximity to nearest trainstation.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "```python\n",
    "# Install required libraries\n",
    "!pip install pandas scikit-learn geopy numpy joblib time \n",
    "````\n",
    "### Author: Aaron Mpuga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f71ef69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os \n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2188270f-edb8-490a-9498-ad1df18fa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes the warning in output cell\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49e61c-83d1-4b58-a46d-2d2afe53d1a8",
   "metadata": {},
   "source": [
    "## Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3771be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Iterates through all the housing sales data excel files in the \"Annualized_Rolling_Sales_Update\" folder and combines them into a single \n",
    "dataframe \n",
    "\n",
    "'''\n",
    "\n",
    "# Path to \"Annualized_Rolling_Sales_Update\" folder\n",
    "rolling_sales_directory = \"/Users/atwoo/Documents/Fairly_even/data/raw_data/Annualized_Rolling_Sales_Update\"\n",
    "\n",
    "file_df_list = []\n",
    "\n",
    "for file in os.listdir(sales_directory):\n",
    "    if file.endswith('.xls') or file.endswith('.xlsx'):\n",
    "        file_path = os.path.join(rolling_sales_directory, file)\n",
    "        df = pd.read_excel(file_path)\n",
    "        file_df_list.append(df)\n",
    "\n",
    "housing_sales_df = pd.concat(file_df_list, ignore_index=True)\n",
    "housing_sales_df.to_csv('housing_sales_data.csv', index=False)\n",
    "\n",
    "print(\"Combined rolling sales CSV created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1323c06-32db-417a-a6cd-068718d68145",
   "metadata": {},
   "source": [
    "\n",
    "**Cleans MTA subway stations csv file taken from \"data.ny.gov\"** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f41a26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleans MTA subway stations csv file taken from \"data.ny.gov\" \n",
    "'''\n",
    "\n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data/raw_data\"\n",
    "\n",
    "station_data_filename = \"MTA_Subway_Stations.csv\"\n",
    "station_data_path = os.path.join(folder_directory, station_data_filename)\n",
    "\n",
    "station_data = pd.read_csv(station_data_path)\n",
    "columns = [\"Borough\",\"Stop Name\",\"GTFS Latitude\", \"GTFS Longitude\", \"Georeference\"]\n",
    "station_data = station_data[columns]\n",
    "\n",
    "##Change borough names##\n",
    "borough_map = {\"M\": \"Manhattan\", \"Bk\" : \"Brooklyn\", \"Bx\" : \"Bronx\", \"Q\" : \"Queens\", \"SI\" : \"Staten Island\"}\n",
    "\n",
    "for row_idx, elem in enumerate(station_data[\"Borough\"]):\n",
    "    if elem in borough_map:\n",
    "        station_data[\"Borough\"][row_idx] = borough_map[elem]\n",
    "        \n",
    "#Change Latitude and Longitude index names\n",
    "station_data.rename(columns= {\"GTFS Latitude\" : \"Station_Latitude\", \"GTFS Longitude\" : \"Station_Longitude\"}, inplace= True)\n",
    "\n",
    "# Save Cleaned station Data as CSV\n",
    "clean_station_data_filename = \"clean_station_data.csv\"\n",
    "clean_path = os.path.join(folder_directory, clean_station_data_filename)\n",
    "station_data.to_csv(clean_path, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f4200-afdb-48b2-a810-dba0afaf9d51",
   "metadata": {},
   "source": [
    "**Cleans the combined housing data csv file that was just created.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce7b7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to \"housing_sales_data\" file \n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data/interim_data\"\n",
    "\n",
    "housing_filename = \"housing_sales_data.csv\"\n",
    "housing_data_path = os.path.join(folder_directory, housing_filename)\n",
    "\n",
    "housing_data = pd.read_csv(housing_data_path, low_memory=False)\n",
    "housing_data = housing_data.drop(housing_data.columns[21:], axis=1)\n",
    "housing_data = housing_data.drop(axis = 0, index= [0,1,2])\n",
    "new_column_names =[\"Borough\",\"Neighborhood\",\"Building_Class_Category\",\"Tax_Class\",\"Tax_Block\",\"Tax_Lot\",\"Easement\", \"Building_Classification_Code_At_Present\",\"Address\",\n",
    "                    \"Apartment_Number\", \"Zip_Code\", \"Residential_Units\", \"Commercial_Units\", \"Total_Units\", \"Land_Square_Feet\", \"Gross_Square_Feet\", \"Year_Built\", \n",
    "                    \"Tax_Class_At_Time_Of_Sale\", \"Building_Classification_Code_At_Time_Of_Sale\", \"Sale_Price\", \"Sale_Date\"]\n",
    "\n",
    "housing_data.columns = new_column_names\n",
    "housing_data = housing_data.drop(axis=0, index=[3])\n",
    "housing_data = housing_data.reset_index(drop= True)\n",
    "\n",
    "# Re-order columns of dataframe\n",
    "columns_kept = [\"Borough\", \"Neighborhood\", \"Building_Class_Category\", \n",
    "    \"Building_Classification_Code_At_Time_Of_Sale\", \"Address\", \"Zip_Code\", \"Sale_Price\", \"Sale_Date\"]\n",
    "housing_data = housing_data[columns_kept]\n",
    "\n",
    "# Used the \"zip_borough.csv\" CSV file to map each property to a borough, given the zip codes of each property in dataframe\n",
    "zip_dir = \"/Users/atwoo/Documents/Fairly_even/data/raw_data\"\n",
    "\n",
    "zip_borough_map_path = os.path.join(zip_dir, \"zip_borough.csv\")\n",
    "zip_to_borough = pd.read_csv(zip_borough_map_path)\n",
    "\n",
    "# Aligning column names and dtype of column cell data before merging\n",
    "zip_to_borough.columns = [\"Zip_Code\", \"Borough\"]\n",
    "housing_data[\"Zip_Code\"] = pd.to_numeric(housing_data[\"Zip_Code\"], errors = \"coerce\")\n",
    "housing_data = housing_data.dropna(subset=[\"Zip_Code\"])\n",
    "housing_data[\"Zip_Code\"] = housing_data[\"Zip_Code\"].astype(\"int64\")\n",
    "housing_data = housing_data.merge(zip_to_borough, on=\"Zip_Code\", how=\"left\")\n",
    "\n",
    "# Removing unmapped zipcode rows and re-ordering columns of dataframe\n",
    "housing_data = housing_data.dropna(subset= [\"Borough_y\"])\n",
    "housing_data = housing_data.drop(columns = [\"Borough_x\"])\n",
    "housing_data = housing_data.rename(columns = {\"Borough_y\": \"Borough\"})\n",
    "housing_data = housing_data[columns_kept]\n",
    "\n",
    "# Removing rows where the sale price is zero (Indication of transfer of ownership involving no money according to glossary)\n",
    "housing_data[\"Sale_Price\"] = housing_data[\"Sale_Price\"].astype(\"int64\")\n",
    "housing_data = housing_data[housing_data[\"Sale_Price\"] != 0]\n",
    "housing_data = housing_data.reset_index(drop= True)\n",
    "\n",
    "# Formating date and time values\n",
    "housing_data[\"Sale_Date\"] = pd.to_datetime(housing_data[\"Sale_Date\"])\n",
    "housing_data[\"Year\"] = housing_data[\"Sale_Date\"].dt.year\n",
    "housing_data = housing_data.sort_values(by= [\"Address\",\"Year\"])\n",
    "\n",
    "# Saving cleaned \"housing_sales_data\" dataframe as CSV file \"cleaned_file_name\"\n",
    "cleaned_file_name = \"Cleaned_NYC_Property_Sales_Data_2003_To_2015.csv\"\n",
    "cleaned_filepath = os.path.join(folder_directory, cleaned_file_name)\n",
    "\n",
    "housing_data.to_csv(cleaned_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b86a3-5dd3-497f-bfcb-061271a22d15",
   "metadata": {},
   "source": [
    "**Data/API Limitation and Scope Reduction:**\n",
    "\n",
    "The original cleaned dataset contained approximately **900,000 rows** of housing sales data from the years **2003-2015**. To manage the project's scope because of how large the dataset was I initially wanted to limit the analysis to properties within the following building codes:\n",
    "\n",
    "- **A**: One Family Dwellings (approx. 162,000 rows)\n",
    "- **B**: Two Family Dwellings (approx. 142,000 rows)\n",
    "- **D**: Elevator Apartments (approx. 166,000 rows)\n",
    "\n",
    "However, after analyzing the number of **unique addresses** within these building codes, I encountered a limitation with the **free Nominatim API**. This API only allows **one address to be processed per second**, meaning that running the script to retrieve longitude and latitude values for all addresses would take about **~17.3 hours** = 62,481 (number of unique addresses) seconds. So, I decided to narrow the scope of the project further by focusing on just properties with building code **A**. Processing just these addresses would reduce the time to **6 hours** (24,205 seconds), making the task more manageable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd45266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_start = (\"A\", \"B\", \"D\")\n",
    "housing_data_codes = housing_data[housing_data[\"Building_Classification_Code_At_Time_Of_Sale\"].str.startswith(codes_start)]\n",
    "rows_to_drop = housing_data_codes[housing_data_codes[\"Address\"].str.len() < 5].index\n",
    "housing_data_codes = housing_data_codes.drop(rows_to_drop)\n",
    "\n",
    "# Group by Address and filter out addresses that appear only once\n",
    "address_duplicate_count = housing_data_codes['Address'].value_counts()\n",
    "repeated_addresses = housing_data_codes['Address'].isin(address_duplicate_count[address_duplicate_count > 1].index)\n",
    "housing_data_codes = housing_data_codes[repeated_addresses]\n",
    "housing_data_codes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create dataframe specific to housing data with building code A\n",
    "housing_data_codeA = housing_data_codes[housing_data_codes[\"Building_Classification_Code_At_Time_Of_Sale\"].str.startswith(\"A\") == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "587baaa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique addresses for building codes A, B and D is: 62481\n",
      "Number of unique addresses for just buildings with code A is: 24205\n"
     ]
    }
   ],
   "source": [
    "count1 = housing_data_codes[\"Address\"].nunique()\n",
    "count2 = housing_data_codeA[\"Address\"].nunique()\n",
    "print(f\"Number of unique addresses for building codes A, B and D is: {count1}\")\n",
    "print(f\"Number of unique addresses for just buildings with code A is: {count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a8cc8-0eb4-4a25-9cf0-4a73d5b9f71a",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045d3a0",
   "metadata": {},
   "source": [
    "**Geocodes (finds the latitude and longitude) for all addresses in the address column of the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64f9a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save backup CSV file every 1800 addresses\n",
    "save_directory = \"/Users/atwoo/Documents/Fairly_even/data/interim_data\"\n",
    "\n",
    "backup_csv_path = os.path.join(save_directory, \"geocoded_addresses_codeA_backup.csv\")\n",
    "final_csv_path = os.path.join(save_directory, \"geocoded_housing_data_codeA_final.csv\")\n",
    "df_path = os.path.join(save_directory, \"housing_data_codeA.csv\")\n",
    "\n",
    "housing_data_codeA = pd.read_csv(df_path)\n",
    "\n",
    "geo = Nominatim(user_agent=\"my_housing_project_app\")\n",
    "\n",
    "# Address cache\n",
    "address_dict = {}\n",
    "\n",
    "def getMeridian(street: str, postalcode: int, city: str, index: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Determines the longitidue and latitude values for a given address\n",
    "    Parameters\n",
    "    ----------\n",
    "    street : str\n",
    "        Street address for the location of the desired latitude and longitude values.\n",
    "    postalcode : int\n",
    "        Postalcode or zipcode  for the location of the desired latitude and longitude values. \n",
    "    city : str\n",
    "        City name for the location of the desired latitude and longitude values. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        latitude and longitude pairing.\n",
    "\n",
    "    \"\"\"\n",
    "    # Construct the structured query dictionary (defined by geopy)\n",
    "    query = {\n",
    "        'street': street,\n",
    "        'postalcode': postalcode,\n",
    "        'city' : city,\n",
    "        'state' : \"NY\"\n",
    "    }\n",
    "\n",
    "    # Convert query dictionary to a string to use as a key for the cache\n",
    "    query_key = str(query)\n",
    "    \n",
    "    # Check if the query has been seen before\n",
    "    if query_key in address_dict:\n",
    "        return address_dict[query_key]\n",
    "    else:\n",
    "        try:\n",
    "            location = geo.geocode(query)\n",
    "            if location:\n",
    "                address_dict[query_key] = (location.latitude, location.longitude)\n",
    "            else:\n",
    "                address_dict[query_key] = (None, None)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't find latitude and longitude for {query_key}: {e}\")\n",
    "            address_dict[query_key] = (None, None)\n",
    "                \n",
    "    if index % 1800 == 0:\n",
    "        print(f\"Processed {index} addresses so far!\")\n",
    "        # Save progress to a backup CSV file every 1800 addresses (approximately every 30 minutes)\n",
    "        pd.DataFrame.from_dict(address_dict, orient=\"index\", columns=[\"Latitude\", \"Longitude\"]).to_csv(backup_csv_path)\n",
    "        \n",
    "    # Rate limiting: pause between requests to avoid hitting the rate limit\n",
    "    time.sleep(1)  \n",
    "    \n",
    "    return address_dict[query_key]\n",
    "\n",
    "# Execute method \n",
    "housing_data_codeA[\"Latitude\"], housing_data_codeA[\"Longitude\"] = zip(*housing_data_codeA.apply(\n",
    "    lambda row: getMeridian(row[\"Address\"], row[\"Zip_Code\"], row[\"Borough\"], row.name), axis=1))\n",
    "\n",
    "housing_data_codeA.to_csv(final_csv_path, index=False)\n",
    "print(f\"Completed! The final data has been saved to data folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc14be",
   "metadata": {},
   "source": [
    "**Creates a CSV file where for a given property row the nearest trainstation's name and its distance from the property are two additional columns added onto the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a496277",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_codeA = pd.read_csv(\"/Users/atwoo/Documents/Fairly_even/data/interim_data/geocoded_housing_data_codeA_final.csv\")\n",
    "\n",
    "geo_codeA.dropna(axis= 0, subset= [\"Latitude\", \"Longitude\"], inplace= True)\n",
    "geo_codeA = geo_codeA.reset_index()\n",
    "station_data = pd.read_csv(\"/Users/atwoo/Documents/Fairly_even/data/processed_data/clean_station_data.csv\")\n",
    "\n",
    "def calculate_distance (latitude_1: float, longitude_1: float, latitude_2: float, longitude_2: float) -> float:\n",
    "    \"\"\"Calculate the distance in meters between two latitude and longitude coordinate points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude_1 : float\n",
    "        latitude value of first coordinate point\n",
    "    longitude_1 : float\n",
    "        longitude value of first coordinate point\n",
    "    latitude_2 : float\n",
    "        latitude value of second coordinate point\n",
    "    longitude_2 : float\n",
    "        longitude value of second coordinate point\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        distance between coordinate points \n",
    "    \"\"\"\n",
    "\n",
    "    return geodesic((latitude_1, longitude_1), (latitude_2, longitude_2)).meters\n",
    "\n",
    "def get_nearest_station (property_latitude: float, property_longitude: float, station_df) -> tuple:\n",
    "    \"\"\"Find the nearest train station name and its distance to the inputted property's latitude and longitude coordinate points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    property_latitude : float\n",
    "        latitude value of the property \n",
    "    property_longitude : float\n",
    "        longitude value of the property        \n",
    "    station_df : csv file \n",
    "        Csv file containing the station data for all train stations in new york. Each row must have a two columns correpsonding to a stations latitude and longitude, \n",
    "        titled Station_Latitude and Station_Longitude respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        returns tuple of station name followed by distance of station to property\n",
    "\n",
    "    \"\"\"\n",
    "    distances = station_df.apply(lambda row: calculate_distance(property_latitude, property_longitude, row[\"Station_Latitude\"], row[\"Station_Longitude\"]), axis=1)\n",
    "    dist_idx = distances.idxmin()\n",
    "    nearest_station = station_df.loc[dist_idx, \"Stop Name\"]\n",
    "    nearest_station_dist = distances.min()\n",
    "\n",
    "    return nearest_station, nearest_station_dist\n",
    "\n",
    "\n",
    "# geo_codeA[[\"Nearest_Station\", \"Station_Distance\"]] = geo_codeA.apply(lambda row: pd.Series(get_nearest_station(row[\"Latitude\"], row[\"Longitude\"], station_data)), axis=1)\n",
    "geo_codeA = geo_codeA.drop(columns=[\"index\"])\n",
    "\n",
    "file_name = \"combined_station_geocode.csv\"\n",
    "save_path = os.path.join(\"/Users/atwoo/Documents/Fairly_even/data/interim_data\",file_name)\n",
    "geo_codeA.to_csv(save_path)\n",
    "print(\"CSV file created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb2f20-da3e-4f3e-91aa-c13e933891e1",
   "metadata": {},
   "source": [
    "**Creates a CSV file where 13 columns are added each representing the price change x amounts of years after the first sale of a property. Cell value is NaN if rows sale data doesn't correspond to x years ahead column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "650f8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Load created CSV file that contains station name and distance \n",
    "combined_df = pd.read_csv(\"/Users/atwoo/Documents/Fairly_even/data/interim_data/combined_station_geocode.csv\")\n",
    "\n",
    "# Function to calculate lag and price change\n",
    "def calculate_price_changes(group):\n",
    "    \"\"\"Calculate the price change  in meters between two latitude and longitude coordinate points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group : dataframe \n",
    "        Dataframe where rows are grouped by Address name\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        returns dataframe where columns for price change after x years has been added\n",
    "    \"\"\"\n",
    "    \n",
    "    group = group.sort_values(by=\"Year\")\n",
    "        \n",
    "    # Loop over all possible pairs of years in the group\n",
    "    for i in range(len(group)):\n",
    "        for j in range(i + 1, len(group)):\n",
    "            year_diff = group.iloc[j]['Year'] - group.iloc[i]['Year']\n",
    "            price_change = group.iloc[j]['Sale_Price'] - group.iloc[i]['Sale_Price']\n",
    "            \n",
    "            # Create a new column name based on the year difference\n",
    "            col_name = f\"Price_Change_{year_diff}_Years\"\n",
    "            group.loc[group.index[j], col_name] = price_change\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the above function to each group of properties\n",
    "df_result = combined_df.groupby(\"Address\").apply(calculate_price_changes)\n",
    "\n",
    "df_result = df_result.reset_index(drop=True)\n",
    "\n",
    "print(\"DONE!\")\n",
    "\n",
    "#Re-order columns in ascending order  \n",
    "price_idx = [\"Price_Change_0_Years\",\"Price_Change_1_Years\",\"Price_Change_2_Years\",\"Price_Change_3_Years\",\"Price_Change_4_Years\",\"Price_Change_5_Years\",\"Price_Change_6_Years\",\"Price_Change_7_Years\",\"Price_Change_8_Years\",\"Price_Change_9_Years\",\"Price_Change_10_Years\",\"Price_Change_11_Years\",\"Price_Change_12_Years\"]\n",
    "reordered_cols = df_result[price_idx]\n",
    "remaining_cols = df_result.drop(columns=price_idx)\n",
    "df_result = pd.concat([remaining_cols, reordered_cols], axis=1)\n",
    "df_result = df_result.drop(columns= ['Unnamed: 0', 'index'])\n",
    "\n",
    "file_name = \"final_df.csv\"\n",
    "save_path = os.path.join(\"/Users/atwoo/Documents/Fairly_even/data/processed_data\",file_name)\n",
    "df_result.to_csv(save_path)\n",
    "print(\"CSV file created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318828b5",
   "metadata": {},
   "source": [
    "**The code below is a sanity check to see how many lag features have been created**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58ed4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with a value for the specified classification codes in column Price_Change_0_Years is: 1766\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_1_Years is: 2665\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_2_Years is: 1432\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_3_Years is: 1135\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_4_Years is: 959\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_5_Years is: 766\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_6_Years is: 633\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_7_Years is: 601\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_8_Years is: 517\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_9_Years is: 381\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_10_Years is: 301\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_11_Years is: 151\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_12_Years is: 62\n"
     ]
    }
   ],
   "source": [
    "classification_codes = [\"A1\", \"A2\" \"A5\"]\n",
    "\n",
    "counts = {}\n",
    "\n",
    "# Iterate over each years_ahead lag feature\n",
    "for i in range(13):\n",
    "    feature_col = f'Price_Change_{i}_Years'\n",
    "    \n",
    "    filtered_df = df_result[\n",
    "        (df_result[\"Building_Classification_Code_At_Time_Of_Sale\"].isin(classification_codes)) & (df_result[feature_col].notna())]\n",
    "    \n",
    "    # Store the count of rows that meet the criteria\n",
    "    counts[feature_col] = len(filtered_df)\n",
    "\n",
    "# Print the results\n",
    "for feature_col, count in counts.items():\n",
    "    print(f\"Number of rows with a value for the specified classification codes in column {feature_col} is: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df7c68-b59d-49b1-a94a-656d00682cf1",
   "metadata": {},
   "source": [
    "**Due to the limited amount of housing sale price data the purpose of this for loop is to ensure a prediction value that is greater than the property value inputted by the user. The goal of this project is to predict property appreciation. As the year increases the less sale price data is available thus, having negative values will disproportionately show price depreciation of property values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a2db4b7-e951-4181-8a04-1fddb4bfdf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 0 has 3032 negative values\n",
      "year 1 has 1440 negative values\n",
      "year 2 has 1178 negative values\n",
      "year 3 has 1194 negative values\n",
      "year 4 has 1190 negative values\n",
      "year 5 has 1053 negative values\n",
      "year 6 has 892 negative values\n",
      "year 7 has 858 negative values\n",
      "year 8 has 720 negative values\n",
      "year 9 has 528 negative values\n",
      "year 10 has 323 negative values\n",
      "year 11 has 105 negative values\n",
      "year 12 has 38 negative values\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    n_col = f'Price_Change_{i}_Years'\n",
    "    print(f\"year {i} has {(df_result[n_col] < 0).sum()} negative values\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd70375f-142d-4ec4-8cca-26bd25588b16",
   "metadata": {},
   "source": [
    "**Check to see which building classification codes have the most sale data avaliable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9ee3f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Building_Classification_Code_At_Time_Of_Sale\n",
       "A0      500\n",
       "A1    16626\n",
       "A2     6228\n",
       "A3      651\n",
       "A4      760\n",
       "A5    15264\n",
       "A6      334\n",
       "A7       20\n",
       "A8        2\n",
       "A9     3867\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows for each building classification code\n",
    "building_code_counts = df_result.groupby('Building_Classification_Code_At_Time_Of_Sale').size()\n",
    "building_code_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb24506",
   "metadata": {},
   "source": [
    "**It appears that the majority of the buildings in the One Family Dwellings Building category (building classification codes that start with \"A\") fall under the classification codes of:**\n",
    "- A1: TWO STORIES - DETACHED SM OR MID\n",
    "- A2: ONE STORY - PERMANENT LIVING QUARTER\n",
    "- A5: ONE FAMILY ATTACHED OR SEMI-DETACHED\n",
    "- A9: MISCELLANEOUS ONE FAMILY\n",
    "\n",
    "**Scope of project will now be limited to analyzing these properties due to lack of sale data for other housing types**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fe602c1-0af1-4a3e-bef9-e7fd56ce1563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0 - 531.0        8846\n",
       "531.0 - 1092.0     8858\n",
       "1092.0 - 1861.0    8845\n",
       "1861.0 - 3357.0    8851\n",
       "3357.0 - 8763.0    8852\n",
       "Name: Station_Distance_Group, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_station_distance(df, num_groups):\n",
    "    \"\"\"Group all the train station distance data into groups  \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        the dataframe containing the station distance data to be parsed  \n",
    "    num_groups : int\n",
    "        the number of groups to split the station distance data into\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        returns dataframe where a new column is added corresponding to the current rows station group\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create quantile-based bins\n",
    "    bins = pd.qcut(df['Station_Distance'], num_groups, retbins=True, duplicates='drop')[1]\n",
    "    \n",
    "    # Round bins to the nearest whole number\n",
    "    rounded_bins = np.round(bins)\n",
    "    \n",
    "    rounded_bins = np.unique(rounded_bins)  \n",
    "\n",
    "    # Define labels as interval ranges\n",
    "    interval_labels = [f'{rounded_bins[i]} - {rounded_bins[i+1]}' for i in range(len(rounded_bins) - 1)]\n",
    "    \n",
    "    # Create a new column in the DataFrame with the interval labels\n",
    "    df['Station_Distance_Group'] = pd.cut(df['Station_Distance'], bins=rounded_bins, labels=interval_labels, include_lowest=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_result = categorize_station_distance(df_result, 5)\n",
    "group_counts = df_result['Station_Distance_Group'].value_counts().sort_index()\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9969721-1c9d-40b1-83c1-156ee1354776",
   "metadata": {},
   "source": [
    "**This checks to see how many feature rows will be used when training each corresponding regression model. Interestingly, Manhattan had little to know housing sale data for \"A\" Building classification codes. This suggests that Manhattan doesn't have two story, one story and one family attached homes.**\n",
    "\n",
    "**As a result the scope of the project will be limited to focusing on New York City properties in Queens, Brooklyn, Staten Island and the Bronx** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a33a97b6-c34b-4e36-b089-cbee85f58a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for Staten, A1, 0 years ahead: 347\n",
      "Number of samples for Staten, A1, 1 years ahead: 655\n",
      "Number of samples for Staten, A1, 2 years ahead: 447\n",
      "Number of samples for Staten, A1, 3 years ahead: 345\n",
      "Number of samples for Staten, A1, 4 years ahead: 298\n",
      "Number of samples for Staten, A1, 5 years ahead: 245\n",
      "Number of samples for Staten, A1, 6 years ahead: 220\n",
      "Number of samples for Staten, A1, 7 years ahead: 203\n",
      "Number of samples for Staten, A1, 8 years ahead: 185\n",
      "Number of samples for Staten, A1, 9 years ahead: 163\n",
      "Number of samples for Staten, A1, 10 years ahead: 143\n",
      "Number of samples for Staten, A1, 11 years ahead: 76\n",
      "Number of samples for Staten, A1, 12 years ahead: 40\n",
      "Number of samples for Staten, A2, 0 years ahead: 148\n",
      "Number of samples for Staten, A2, 1 years ahead: 278\n",
      "Number of samples for Staten, A2, 2 years ahead: 180\n",
      "Number of samples for Staten, A2, 3 years ahead: 139\n",
      "Number of samples for Staten, A2, 4 years ahead: 115\n",
      "Number of samples for Staten, A2, 5 years ahead: 115\n",
      "Number of samples for Staten, A2, 6 years ahead: 94\n",
      "Number of samples for Staten, A2, 7 years ahead: 83\n",
      "Number of samples for Staten, A2, 8 years ahead: 76\n",
      "Number of samples for Staten, A2, 9 years ahead: 67\n",
      "Number of samples for Staten, A2, 10 years ahead: 54\n",
      "Number of samples for Staten, A2, 11 years ahead: 33\n",
      "Number of samples for Staten, A2, 12 years ahead: 12\n",
      "Number of samples for Staten, A5, 0 years ahead: 559\n",
      "Number of samples for Staten, A5, 1 years ahead: 681\n",
      "Number of samples for Staten, A5, 2 years ahead: 618\n",
      "Number of samples for Staten, A5, 3 years ahead: 565\n",
      "Number of samples for Staten, A5, 4 years ahead: 535\n",
      "Number of samples for Staten, A5, 5 years ahead: 473\n",
      "Number of samples for Staten, A5, 6 years ahead: 402\n",
      "Number of samples for Staten, A5, 7 years ahead: 337\n",
      "Number of samples for Staten, A5, 8 years ahead: 310\n",
      "Number of samples for Staten, A5, 9 years ahead: 336\n",
      "Number of samples for Staten, A5, 10 years ahead: 272\n",
      "Number of samples for Staten, A5, 11 years ahead: 187\n",
      "Number of samples for Staten, A5, 12 years ahead: 86\n",
      "Number of samples for Bronx, A1, 0 years ahead: 201\n",
      "Number of samples for Bronx, A1, 1 years ahead: 293\n",
      "Number of samples for Bronx, A1, 2 years ahead: 136\n",
      "Number of samples for Bronx, A1, 3 years ahead: 108\n",
      "Number of samples for Bronx, A1, 4 years ahead: 93\n",
      "Number of samples for Bronx, A1, 5 years ahead: 74\n",
      "Number of samples for Bronx, A1, 6 years ahead: 69\n",
      "Number of samples for Bronx, A1, 7 years ahead: 81\n",
      "Number of samples for Bronx, A1, 8 years ahead: 57\n",
      "Number of samples for Bronx, A1, 9 years ahead: 45\n",
      "Number of samples for Bronx, A1, 10 years ahead: 46\n",
      "Number of samples for Bronx, A1, 11 years ahead: 21\n",
      "Number of samples for Bronx, A1, 12 years ahead: 12\n",
      "Number of samples for Bronx, A2, 0 years ahead: 66\n",
      "Number of samples for Bronx, A2, 1 years ahead: 96\n",
      "Number of samples for Bronx, A2, 2 years ahead: 69\n",
      "Number of samples for Bronx, A2, 3 years ahead: 40\n",
      "Number of samples for Bronx, A2, 4 years ahead: 26\n",
      "Number of samples for Bronx, A2, 5 years ahead: 26\n",
      "Number of samples for Bronx, A2, 6 years ahead: 24\n",
      "Number of samples for Bronx, A2, 7 years ahead: 23\n",
      "Number of samples for Bronx, A2, 8 years ahead: 20\n",
      "Number of samples for Bronx, A2, 9 years ahead: 18\n",
      "Number of samples for Bronx, A2, 10 years ahead: 11\n",
      "Number of samples for Bronx, A2, 11 years ahead: 13\n",
      "Number of samples for Bronx, A2, 12 years ahead: 6\n",
      "Number of samples for Bronx, A5, 0 years ahead: 200\n",
      "Number of samples for Bronx, A5, 1 years ahead: 244\n",
      "Number of samples for Bronx, A5, 2 years ahead: 156\n",
      "Number of samples for Bronx, A5, 3 years ahead: 102\n",
      "Number of samples for Bronx, A5, 4 years ahead: 122\n",
      "Number of samples for Bronx, A5, 5 years ahead: 66\n",
      "Number of samples for Bronx, A5, 6 years ahead: 46\n",
      "Number of samples for Bronx, A5, 7 years ahead: 62\n",
      "Number of samples for Bronx, A5, 8 years ahead: 57\n",
      "Number of samples for Bronx, A5, 9 years ahead: 30\n",
      "Number of samples for Bronx, A5, 10 years ahead: 45\n",
      "Number of samples for Bronx, A5, 11 years ahead: 24\n",
      "Number of samples for Bronx, A5, 12 years ahead: 15\n",
      "Number of samples for Queens, A1, 0 years ahead: 1019\n",
      "Number of samples for Queens, A1, 1 years ahead: 1432\n",
      "Number of samples for Queens, A1, 2 years ahead: 693\n",
      "Number of samples for Queens, A1, 3 years ahead: 549\n",
      "Number of samples for Queens, A1, 4 years ahead: 442\n",
      "Number of samples for Queens, A1, 5 years ahead: 351\n",
      "Number of samples for Queens, A1, 6 years ahead: 269\n",
      "Number of samples for Queens, A1, 7 years ahead: 247\n",
      "Number of samples for Queens, A1, 8 years ahead: 206\n",
      "Number of samples for Queens, A1, 9 years ahead: 104\n",
      "Number of samples for Queens, A1, 10 years ahead: 71\n",
      "Number of samples for Queens, A1, 11 years ahead: 27\n",
      "Number of samples for Queens, A1, 12 years ahead: 0\n",
      "Number of samples for Queens, A2, 0 years ahead: 303\n",
      "Number of samples for Queens, A2, 1 years ahead: 428\n",
      "Number of samples for Queens, A2, 2 years ahead: 174\n",
      "Number of samples for Queens, A2, 3 years ahead: 119\n",
      "Number of samples for Queens, A2, 4 years ahead: 109\n",
      "Number of samples for Queens, A2, 5 years ahead: 73\n",
      "Number of samples for Queens, A2, 6 years ahead: 84\n",
      "Number of samples for Queens, A2, 7 years ahead: 73\n",
      "Number of samples for Queens, A2, 8 years ahead: 34\n",
      "Number of samples for Queens, A2, 9 years ahead: 40\n",
      "Number of samples for Queens, A2, 10 years ahead: 21\n",
      "Number of samples for Queens, A2, 11 years ahead: 6\n",
      "Number of samples for Queens, A2, 12 years ahead: 1\n",
      "Number of samples for Queens, A5, 0 years ahead: 422\n",
      "Number of samples for Queens, A5, 1 years ahead: 538\n",
      "Number of samples for Queens, A5, 2 years ahead: 306\n",
      "Number of samples for Queens, A5, 3 years ahead: 233\n",
      "Number of samples for Queens, A5, 4 years ahead: 172\n",
      "Number of samples for Queens, A5, 5 years ahead: 176\n",
      "Number of samples for Queens, A5, 6 years ahead: 139\n",
      "Number of samples for Queens, A5, 7 years ahead: 110\n",
      "Number of samples for Queens, A5, 8 years ahead: 100\n",
      "Number of samples for Queens, A5, 9 years ahead: 81\n",
      "Number of samples for Queens, A5, 10 years ahead: 46\n",
      "Number of samples for Queens, A5, 11 years ahead: 11\n",
      "Number of samples for Queens, A5, 12 years ahead: 4\n",
      "Number of samples for Brooklyn, A1, 0 years ahead: 199\n",
      "Number of samples for Brooklyn, A1, 1 years ahead: 285\n",
      "Number of samples for Brooklyn, A1, 2 years ahead: 156\n",
      "Number of samples for Brooklyn, A1, 3 years ahead: 133\n",
      "Number of samples for Brooklyn, A1, 4 years ahead: 126\n",
      "Number of samples for Brooklyn, A1, 5 years ahead: 96\n",
      "Number of samples for Brooklyn, A1, 6 years ahead: 75\n",
      "Number of samples for Brooklyn, A1, 7 years ahead: 70\n",
      "Number of samples for Brooklyn, A1, 8 years ahead: 69\n",
      "Number of samples for Brooklyn, A1, 9 years ahead: 69\n",
      "Number of samples for Brooklyn, A1, 10 years ahead: 41\n",
      "Number of samples for Brooklyn, A1, 11 years ahead: 27\n",
      "Number of samples for Brooklyn, A1, 12 years ahead: 10\n",
      "Number of samples for Brooklyn, A2, 0 years ahead: 68\n",
      "Number of samples for Brooklyn, A2, 1 years ahead: 95\n",
      "Number of samples for Brooklyn, A2, 2 years ahead: 59\n",
      "Number of samples for Brooklyn, A2, 3 years ahead: 43\n",
      "Number of samples for Brooklyn, A2, 4 years ahead: 28\n",
      "Number of samples for Brooklyn, A2, 5 years ahead: 29\n",
      "Number of samples for Brooklyn, A2, 6 years ahead: 18\n",
      "Number of samples for Brooklyn, A2, 7 years ahead: 19\n",
      "Number of samples for Brooklyn, A2, 8 years ahead: 15\n",
      "Number of samples for Brooklyn, A2, 9 years ahead: 19\n",
      "Number of samples for Brooklyn, A2, 10 years ahead: 20\n",
      "Number of samples for Brooklyn, A2, 11 years ahead: 8\n",
      "Number of samples for Brooklyn, A2, 12 years ahead: 3\n",
      "Number of samples for Brooklyn, A5, 0 years ahead: 270\n",
      "Number of samples for Brooklyn, A5, 1 years ahead: 378\n",
      "Number of samples for Brooklyn, A5, 2 years ahead: 204\n",
      "Number of samples for Brooklyn, A5, 3 years ahead: 146\n",
      "Number of samples for Brooklyn, A5, 4 years ahead: 140\n",
      "Number of samples for Brooklyn, A5, 5 years ahead: 130\n",
      "Number of samples for Brooklyn, A5, 6 years ahead: 116\n",
      "Number of samples for Brooklyn, A5, 7 years ahead: 106\n",
      "Number of samples for Brooklyn, A5, 8 years ahead: 87\n",
      "Number of samples for Brooklyn, A5, 9 years ahead: 82\n",
      "Number of samples for Brooklyn, A5, 10 years ahead: 56\n",
      "Number of samples for Brooklyn, A5, 11 years ahead: 39\n",
      "Number of samples for Brooklyn, A5, 12 years ahead: 12\n",
      "Number of samples for Manhattan, A1, 0 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 1 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 2 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 3 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 4 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 5 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 6 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 7 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 8 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 9 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 10 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 11 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 12 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 0 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 1 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 2 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 3 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 4 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 5 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 6 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 7 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 8 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 9 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 10 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 11 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 12 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 0 years ahead: 1\n",
      "Number of samples for Manhattan, A5, 1 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 2 years ahead: 3\n",
      "Number of samples for Manhattan, A5, 3 years ahead: 2\n",
      "Number of samples for Manhattan, A5, 4 years ahead: 2\n",
      "Number of samples for Manhattan, A5, 5 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 6 years ahead: 1\n",
      "Number of samples for Manhattan, A5, 7 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 8 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 9 years ahead: 1\n",
      "Number of samples for Manhattan, A5, 10 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 11 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 12 years ahead: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data/processed_data\"\n",
    "file_name = \"final_df.csv\"\n",
    "data_path = os.path.join(folder_directory, file_name)\n",
    "\n",
    "df_result = pd.read_csv(data_path)\n",
    "\n",
    "# List of popular building classification codes\n",
    "popular_codes = ['A1', 'A2', 'A5']  # Replace with actual codes\n",
    "\n",
    "# List of boroughs\n",
    "boroughs = df_result['Borough'].unique()\n",
    "\n",
    "# Iterate over each borough, building classification code, and years_ahead lag feature\n",
    "for borough in boroughs:\n",
    "    for building_code in popular_codes:\n",
    "        for i in range(13):\n",
    "            feature_col = f'Price_Change_{i}_Years'\n",
    "            \n",
    "            # Filter rows for the given borough and building code and where the feature is not NaN\n",
    "            df_nonan = df_result.dropna(subset=[feature_col])\n",
    "            df_filtered = df_nonan[\n",
    "                (df_nonan['Building_Classification_Code_At_Time_Of_Sale'] == building_code) &\n",
    "                (df_nonan['Borough'] == borough)\n",
    "            ]\n",
    "\n",
    "            # Define X (features) and y (target)\n",
    "            numerical_features = df_filtered[['Sale_Price', 'Station_Distance']]  # Include numeric variables\n",
    "\n",
    "            # Combine numerical and categorical features\n",
    "            features = numerical_features\n",
    "\n",
    "            # Target variable\n",
    "            target = df_filtered[feature_col]  # Target is the price change\n",
    "\n",
    "            # Ensure features and target have no missing values\n",
    "            features = features.dropna()\n",
    "            target = target.loc[features.index]\n",
    "\n",
    "            # Print the number of samples\n",
    "            num_samples = len(features)\n",
    "            print(f\"Number of samples for {borough}, {building_code}, {i} years ahead: {num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa69fdd-ebc9-4849-afc2-932abcc124e3",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1a6be02-df85-40bf-a894-beb1d87e90df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Staten, A1 0 years ahead was saved.\n",
      "Model for Staten, A1 1 years ahead was saved.\n",
      "Model for Staten, A1 2 years ahead was saved.\n",
      "Model for Staten, A1 3 years ahead was saved.\n",
      "Model for Staten, A1 4 years ahead was saved.\n",
      "Model for Staten, A1 5 years ahead was saved.\n",
      "Model for Staten, A5 0 years ahead was saved.\n",
      "Model for Staten, A5 1 years ahead was saved.\n",
      "Model for Staten, A5 2 years ahead was saved.\n",
      "Model for Staten, A5 3 years ahead was saved.\n",
      "Model for Staten, A5 4 years ahead was saved.\n",
      "Model for Staten, A5 5 years ahead was saved.\n",
      "Model for Staten, A2 0 years ahead was saved.\n",
      "Model for Staten, A2 1 years ahead was saved.\n",
      "Model for Staten, A2 2 years ahead was saved.\n",
      "Model for Staten, A2 3 years ahead was saved.\n",
      "Model for Staten, A2 4 years ahead was saved.\n",
      "Model for Staten, A2 5 years ahead was saved.\n",
      "Model for Queens, A1 0 years ahead was saved.\n",
      "Model for Queens, A1 1 years ahead was saved.\n",
      "Model for Queens, A1 2 years ahead was saved.\n",
      "Model for Queens, A1 3 years ahead was saved.\n",
      "Model for Queens, A1 4 years ahead was saved.\n",
      "Model for Queens, A1 5 years ahead was saved.\n",
      "Model for Queens, A5 0 years ahead was saved.\n",
      "Model for Queens, A5 1 years ahead was saved.\n",
      "Model for Queens, A5 2 years ahead was saved.\n",
      "Model for Queens, A5 3 years ahead was saved.\n",
      "Model for Queens, A5 4 years ahead was saved.\n",
      "Model for Queens, A5 5 years ahead was saved.\n",
      "Model for Queens, A2 0 years ahead was saved.\n",
      "Model for Queens, A2 1 years ahead was saved.\n",
      "Model for Queens, A2 2 years ahead was saved.\n",
      "Model for Queens, A2 3 years ahead was saved.\n",
      "Model for Queens, A2 4 years ahead was saved.\n",
      "Model for Queens, A2 5 years ahead was saved.\n",
      "Model for Bronx, A1 0 years ahead was saved.\n",
      "Model for Bronx, A1 1 years ahead was saved.\n",
      "Model for Bronx, A1 2 years ahead was saved.\n",
      "Model for Bronx, A1 3 years ahead was saved.\n",
      "Model for Bronx, A1 4 years ahead was saved.\n",
      "Model for Bronx, A1 5 years ahead was saved.\n",
      "Model for Bronx, A5 0 years ahead was saved.\n",
      "Model for Bronx, A5 1 years ahead was saved.\n",
      "Model for Bronx, A5 2 years ahead was saved.\n",
      "Model for Bronx, A5 3 years ahead was saved.\n",
      "Model for Bronx, A5 4 years ahead was saved.\n",
      "Model for Bronx, A5 5 years ahead was saved.\n",
      "Model for Bronx, A2 0 years ahead was saved.\n",
      "Model for Bronx, A2 1 years ahead was saved.\n",
      "Model for Bronx, A2 2 years ahead was saved.\n",
      "Model for Bronx, A2 3 years ahead was saved.\n",
      "Model for Bronx, A2 4 years ahead was saved.\n",
      "Model for Bronx, A2 5 years ahead was saved.\n",
      "Model for Brooklyn, A1 0 years ahead was saved.\n",
      "Model for Brooklyn, A1 1 years ahead was saved.\n",
      "Model for Brooklyn, A1 2 years ahead was saved.\n",
      "Model for Brooklyn, A1 3 years ahead was saved.\n",
      "Model for Brooklyn, A1 4 years ahead was saved.\n",
      "Model for Brooklyn, A1 5 years ahead was saved.\n",
      "Model for Brooklyn, A5 0 years ahead was saved.\n",
      "Model for Brooklyn, A5 1 years ahead was saved.\n",
      "Model for Brooklyn, A5 2 years ahead was saved.\n",
      "Model for Brooklyn, A5 3 years ahead was saved.\n",
      "Model for Brooklyn, A5 4 years ahead was saved.\n",
      "Model for Brooklyn, A5 5 years ahead was saved.\n",
      "Model for Brooklyn, A2 0 years ahead was saved.\n",
      "Model for Brooklyn, A2 1 years ahead was saved.\n",
      "Model for Brooklyn, A2 2 years ahead was saved.\n",
      "Model for Brooklyn, A2 3 years ahead was saved.\n",
      "Model for Brooklyn, A2 4 years ahead was saved.\n",
      "Model for Brooklyn, A2 5 years ahead was saved.\n"
     ]
    }
   ],
   "source": [
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data/processed_data\"\n",
    "file_name = \"final_df.csv\"\n",
    "data_path = os.path.join(folder_directory, file_name)\n",
    "\n",
    "df_result = pd.read_csv(data_path)\n",
    "\n",
    "# List of popular building classification codes\n",
    "popular_codes = ['A1', 'A5', 'A2']  # Replace with actual codes\n",
    "\n",
    "# List of boroughs\n",
    "boroughs = [\"Staten\", \"Queens\", \"Bronx\", \"Brooklyn\"]\n",
    "\n",
    "#This removes all values in price change x years columns that are less than 0 \n",
    "for i in range(13):\n",
    "    n_col = f'Price_Change_{i}_Years'\n",
    "    df_result[n_col] = df_result[n_col].apply(lambda x: 0 if x < 0 else x) \n",
    "\n",
    "\n",
    "# Iterate over each borough, building classification code, and years_ahead lag feature\n",
    "for borough in boroughs:\n",
    "    for building_code in popular_codes:\n",
    "        for i in range(6):\n",
    "            feature_col = f'Price_Change_{i}_Years'\n",
    "            \n",
    "            # Drop rows where price change column i year's value is NaN indicating that the dropped row didnt \n",
    "            # have a price change value for the desired i years ahead \n",
    "        \n",
    "            df_nonan = df_result.dropna(subset=[feature_col])\n",
    "            df_filtered = df_nonan[ (df_nonan['Building_Classification_Code_At_Time_Of_Sale'] == building_code) & \n",
    "                                        (df_nonan['Borough'] == borough)]\n",
    "\n",
    "            # Define X (features) and y (target)\n",
    "            numerical_features = df_filtered[['Sale_Price', 'Station_Distance']]\n",
    "\n",
    "            # Combine numerical and categorical features\n",
    "            features = numerical_features\n",
    "\n",
    "            # Target variable is the values in price change i years column\n",
    "            target = df_filtered[feature_col]  \n",
    "\n",
    "            # Ensure features and target have no missing values\n",
    "            features = features.dropna()\n",
    "            target = target.loc[features.index]\n",
    "\n",
    "            # Check if data is available after processing\n",
    "            if features.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # Train-test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=23)\n",
    "\n",
    "            # Initialize and train the model\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Save the model with borough, building_code, and years_ahead in the filename\n",
    "            model_filename = f'model_{borough}_{building_code}_years_ahead_{i}.pkl'\n",
    "            model_dir = \"/Users/atwoo/Documents/Fairly_even/models\"\n",
    "            model_filepath = os.path.join(model_dir, model_filename)\n",
    "            joblib.dump(model, model_filepath)\n",
    "\n",
    "            print(f\"Model for {borough}, {building_code} {i} years ahead was saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224f0b4-c49d-4a26-b2e3-26a1622583a6",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e490bf81-943b-407d-8ce5-21d7a6935d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted property value in 5 years is: 400661.57\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def predict_property_value(current_property_value, years_ahead, building_code, borough, station_distance):\n",
    "    \"\"\"Predict the increase in property value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    current_property_value : float\n",
    "        Current value of property being passed in  \n",
    "    year_ahead : int\n",
    "        The number of years ahead that user wants to predict the value of their property will be         \n",
    "    building_code : string\n",
    "        The building classification code of the property to be predicted\n",
    "    borough : string \n",
    "        The borough of where the property is located \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        returns the predicted property value \n",
    "    \"\"\"\n",
    "\n",
    "    # Validate the years_ahead parameter\n",
    "    if years_ahead < 0 or years_ahead > 5:\n",
    "        raise ValueError(\"Years ahead must be between 0 and 5.\")\n",
    "\n",
    "    # Load the corresponding model based on borough, building code, and years ahead\n",
    "    model_filename = f'model_{borough}_{building_code}_years_ahead_{years_ahead}.pkl'\n",
    "    model_path = os.path.join(\"/Users/atwoo/Documents/Fairly_even/models\", model_filename)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"The model for {borough}, {building_code}, {years_ahead} years ahead does not exist.\")\n",
    "    \n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # Prepare the input data\n",
    "    input_data = pd.DataFrame({\n",
    "        'Sale_Price': [current_property_value],\n",
    "        'Station_Distance': [station_distance],\n",
    "    })\n",
    "    \n",
    "    # Make the prediction using the loaded model\n",
    "    predicted_price_change = model.predict(input_data)[0]\n",
    "    \n",
    "    # Calculate the predicted future property value\n",
    "    future_property_value = current_property_value + predicted_price_change\n",
    "    \n",
    "    return future_property_value\n",
    "\n",
    "# Example usage:\n",
    "curr_price = 300000  # Current property value input by the user\n",
    "years = 5 # How many years ahead the user wants to predict\n",
    "b_code = \"A1\"     # Building classification code of user's property\n",
    "borough = \"Queens\"      # The borough the property is in\n",
    "station_dist = 500   # Distance of the property from the station in meters\n",
    "\n",
    "predicted_value = predict_property_value(curr_price, years, b_code, borough, station_dist)\n",
    "print(f\"The predicted property value in {years_ahead} years is: {predicted_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
