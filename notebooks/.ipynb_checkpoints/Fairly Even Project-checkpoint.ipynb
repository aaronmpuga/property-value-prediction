{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c17c6eb-990b-4586-b862-bf758eae4474",
   "metadata": {},
   "source": [
    "# Property value Prediction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook documents the process of creating randomforest regression models to the value of various property types New York City based on the properties proximity to nearest trainstation.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "```python\n",
    "# Install required libraries\n",
    "!pip install pandas scikit-learn geopy numpy joblib time \n",
    "````\n",
    "### Author: Aaron Mpuga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71ef69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import time\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2188270f-edb8-490a-9498-ad1df18fa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes the warning in output cell\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49e61c-83d1-4b58-a46d-2d2afe53d1a8",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae1c51",
   "metadata": {},
   "source": [
    "Script Below iterates through all the housing sales data files in the \"Annualized_Rolling_Sales_Update\" folder and combines them into a single dataframe. Then saves dataframe as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3771be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "sales_directory = \"/Users/atwoo/Documents/Fairly_even/Annualized_Rolling_Sales_Update\"\n",
    "\n",
    "file_df_list = []\n",
    "\n",
    "for file in os.listdir(sales_directory):\n",
    "    if file.endswith('.xls') or file.endswith('.xlsx'):\n",
    "        file_path = os.path.join(sales_directory, file)\n",
    "        df = pd.read_excel(file_path)\n",
    "        file_df_list.append(df)\n",
    "\n",
    "housing_sales_df = pd.concat(file_df_list, ignore_index=True)\n",
    "housing_sales_df.to_csv('housing_sales_data.csv', index=False)\n",
    "\n",
    "print(\"CSV created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7b7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data\"\n",
    "\n",
    "housing_filename = \"housing_sales_data.csv\"\n",
    "housing_data_path = os.path.join(folder_directory, housing_filename)\n",
    "\n",
    "\n",
    "\n",
    "housing_data = pd.read_csv(housing_data_path, low_memory=False)\n",
    "housing_data = housing_data.drop(housing_data.columns[21:], axis=1)\n",
    "housing_data = housing_data.drop(axis = 0, index= [0,1,2])\n",
    "new_column_names =[\"Borough\",\"Neighborhood\",\"Building_Class_Category\",\"Tax_Class\",\"Tax_Block\",\"Tax_Lot\",\"Easement\", \"Building_Classification_Code_At_Present\",\"Address\",\n",
    "                    \"Apartment_Number\", \"Zip_Code\", \"Residential_Units\", \"Commercial_Units\", \"Total_Units\", \"Land_Square_Feet\", \"Gross_Square_Feet\", \"Year_Built\", \n",
    "                    \"Tax_Class_At_Time_Of_Sale\", \"Building_Classification_Code_At_Time_Of_Sale\", \"Sale_Price\", \"Sale_Date\"]\n",
    "\n",
    "housing_data.columns = new_column_names\n",
    "housing_data = housing_data.drop(axis=0, index=[3])\n",
    "housing_data = housing_data.reset_index(drop= True)\n",
    "\n",
    "#Re-order columns of dataframe\n",
    "columns_kept = [\"Borough\", \"Neighborhood\", \"Building_Class_Category\", \n",
    "    \"Building_Classification_Code_At_Time_Of_Sale\", \"Address\", \"Zip_Code\", \"Sale_Price\", \"Sale_Date\"]\n",
    "housing_data = housing_data[columns_kept]\n",
    "\n",
    "#Used this CSV file to map each property to a borough, given the zip codes of each property in dataframe\n",
    "zip_borough_map_path = os.path.join(folder_directory, \"zip_borough.csv\")\n",
    "zip_to_borough = pd.read_csv(zip_borough_map_path)\n",
    "\n",
    "#Aligning column names and dtype of column cell data before merging\n",
    "zip_to_borough.columns = [\"Zip_Code\", \"Borough\"]\n",
    "housing_data[\"Zip_Code\"] = pd.to_numeric(housing_data[\"Zip_Code\"], errors = \"coerce\")\n",
    "housing_data = housing_data.dropna(subset=[\"Zip_Code\"])\n",
    "housing_data[\"Zip_Code\"] = housing_data[\"Zip_Code\"].astype(\"int64\")\n",
    "housing_data = housing_data.merge(zip_to_borough, on=\"Zip_Code\", how=\"left\")\n",
    "\n",
    "#Removing unmapped zipcode rows and re-ordering columns of dataframe\n",
    "housing_data = housing_data.dropna(subset= [\"Borough_y\"])\n",
    "housing_data = housing_data.drop(columns = [\"Borough_x\"])\n",
    "housing_data = housing_data.rename(columns = {\"Borough_y\": \"Borough\"})\n",
    "housing_data = housing_data[columns_kept]\n",
    "\n",
    "#Removing rows where the sale price is zero (Indication of transfer of ownership involving no money)\n",
    "housing_data[\"Sale_Price\"] = housing_data[\"Sale_Price\"].astype(\"int64\")\n",
    "housing_data = housing_data[housing_data[\"Sale_Price\"] != 0]\n",
    "housing_data = housing_data.reset_index(drop= True)\n",
    "\n",
    "#Formating date and time values\n",
    "housing_data[\"Sale_Date\"] = pd.to_datetime(housing_data[\"Sale_Date\"])\n",
    "housing_data[\"Year\"] = housing_data[\"Sale_Date\"].dt.year\n",
    "housing_data = housing_data.sort_values(by= [\"Address\",\"Year\"])\n",
    "\n",
    "#Saving cleaned dataframe as CSV file\n",
    "\n",
    "# cleaned_file_name = \"Cleaned_NYC_Property_Sales_Data_2003_To_2015.csv\"\n",
    "# cleaned_filepath = os.path.join(folder_directory, cleaned_file_name)\n",
    "# housing_data.to_csv(cleaned_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45f81f",
   "metadata": {},
   "source": [
    "CLEANING OF STATION DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41a26fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zy/k_z06qxx3j35qmc826ygwtx40000gn/T/ipykernel_21854/2101178994.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_data[\"Borough\"][row_idx] = borough_map[elem]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data\"\n",
    "\n",
    "station_data_filename = \"MTA_Subway_Stations.csv\"\n",
    "station_data_path = os.path.join(folder_directory, station_data_filename)\n",
    "\n",
    "station_data = pd.read_csv(station_data_path)\n",
    "columns = [\"Borough\",\"Stop Name\",\"GTFS Latitude\", \"GTFS Longitude\", \"Georeference\"]\n",
    "station_data = station_data[columns]\n",
    "\n",
    "##Change borough names##\n",
    "borough_map = {\"M\": \"Manhattan\", \"Bk\" : \"Brooklyn\", \"Bx\" : \"Bronx\", \"Q\" : \"Queens\", \"SI\" : \"Staten Island\"}\n",
    "\n",
    "for row_idx, elem in enumerate(station_data[\"Borough\"]):\n",
    "    if elem in borough_map:\n",
    "        station_data[\"Borough\"][row_idx] = borough_map[elem]\n",
    "        \n",
    "#Change Latitude and Longitude index names\n",
    "station_data.rename(columns= {\"GTFS Latitude\" : \"Station_Latitude\", \"GTFS Longitude\" : \"Station_Longitude\"}, inplace= True)\n",
    "\n",
    "#Save Cleaned station Data as CSV\n",
    "\n",
    "# clean_station_data_filename = \"clean_station_data.csv\"\n",
    "# clean_path = os.path.join(folder_directory, clean_station_data_filename)\n",
    "# station_data.to_csv(clean_path, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e94832",
   "metadata": {},
   "source": [
    "BUILDING CODES selected to minimize scope of project:\n",
    "- A: One Family Dwellings (Houses) (162,000 rows)\n",
    "- B: Two Family Dwellings (Houses) (142,000 rows)\n",
    "- D: Elevator Apartments (apartments with numbers) (166534 rows)\n",
    "- approx. 478,000 rows total (address with sales for a single year)\n",
    "- approx. 144,000 rows total (address with sales across over 2 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd45266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_start = (\"A\", \"B\", \"D\")\n",
    "housing_data_codes = housing_data[housing_data[\"Building_Classification_Code_At_Time_Of_Sale\"].str.startswith(codes_start)]\n",
    "rows_to_drop = housing_data_codes[housing_data_codes[\"Address\"].str.len() < 5].index\n",
    "housing_data_codes = housing_data_codes.drop(rows_to_drop)\n",
    "\n",
    "# Group by Address and filter out addresses that appear only once\n",
    "address_duplicate_count = housing_data_codes['Address'].value_counts()\n",
    "repeated_addresses = housing_data_codes['Address'].isin(address_duplicate_count[address_duplicate_count > 1].index)\n",
    "housing_data_codes = housing_data_codes[repeated_addresses]\n",
    "housing_data_codes.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "553d0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data_codeA = housing_data_codes[housing_data_codes[\"Building_Classification_Code_At_Time_Of_Sale\"].str.startswith(\"A\") == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243acf39",
   "metadata": {},
   "source": [
    "Based on the number of unique addresses in both dataframes and the limitations of the free Nominatim API. The scope of this project will just focus on properties with buildings starting with A. Since the API can only process one address per second running the script below to get the longitude and latitude values of each address in the codes A, B and D dataframe would take 17.3 hours (62481 seconds) but the dataframe of just code A would take 6 hours (24205 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587baaa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique addresses for building codes A, B and D is: 62481\n",
      "Number of unique addresses for just buildings with code A is: 24205\n"
     ]
    }
   ],
   "source": [
    "count1 = housing_data_codes[\"Address\"].nunique()\n",
    "count2 = housing_data_codeA[\"Address\"].nunique()\n",
    "print(f\"Number of unique addresses for building codes A, B and D is: {count1}\")\n",
    "print(f\"Number of unique addresses for just buildings with code A is: {count2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045d3a0",
   "metadata": {},
   "source": [
    "The script below geocodes (finds the latitude and longitude) all the addresses in the address column of the dataframe for a given csv file. For the purposes of this project the script will geocode addresses with building classification codes starting with the letter A. Since the CSV file read to the script at the start only contains property sale data where the building classifcation starts with the letter A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64f9a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import os \n",
    "\n",
    "# Path to save backup CSV file every 1800 addresses\n",
    "save_directory = \"/Users/atwoo/Documents/Fairly_even/data\"\n",
    "backup_csv_path = os.path.join(save_directory, \"geocoded_addresses_codeA_backup.csv\")\n",
    "final_csv_path = os.path.join(save_directory, \"geocoded_housing_data_codeA_final.csv\")\n",
    "df_path = os.path.join(save_directory, \"housing_data_codeA.csv\")\n",
    "\n",
    "housing_data_codeA = pd.read_csv(df_path)\n",
    "\n",
    "geo = Nominatim(user_agent=\"my_housing_project_app\")\n",
    "\n",
    "# Address cache\n",
    "address_dict = {}\n",
    "\n",
    "def getMeridian(street: str, postalcode: int, city: str, index: int) -> tuple:\n",
    "    \"\"\"Convert `text` (bytestring in given encoding or unicode) to unicode.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    street : str\n",
    "        Street address for the location of the desired latitude and longitude values.\n",
    "    postalcode : int\n",
    "        Postalcode or zipcode  for the location of the desired latitude and longitude values. \n",
    "    city : str\n",
    "        City name for the location of the desired latitude and longitude values. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        latitude and longitude pairing.\n",
    "\n",
    "    \"\"\"\n",
    "    # Construct the structured query dictionary (defined by geopy)\n",
    "    query = {\n",
    "        'street': street,\n",
    "        'postalcode': postalcode,\n",
    "        'city' : city,\n",
    "        'state' : \"NY\"\n",
    "    }\n",
    "\n",
    "    # Convert query dictionary to a string to use as a key for the cache\n",
    "    query_key = str(query)\n",
    "    \n",
    "    # Check if the query has been seen before\n",
    "    if query_key in address_dict:\n",
    "        return address_dict[query_key]\n",
    "    else:\n",
    "        try:\n",
    "            location = geo.geocode(query)\n",
    "            if location:\n",
    "                address_dict[query_key] = (location.latitude, location.longitude)\n",
    "            else:\n",
    "                address_dict[query_key] = (None, None)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't find latitude and longitude for {query_key}: {e}\")\n",
    "            address_dict[query_key] = (None, None)\n",
    "                \n",
    "    if index % 1800 == 0:\n",
    "        print(f\"Processed {index} addresses so far!\")\n",
    "        # Save progress to a backup CSV file every 1800 addresses (approximately every 30 minutes)\n",
    "        pd.DataFrame.from_dict(address_dict, orient=\"index\", columns=[\"Latitude\", \"Longitude\"]).to_csv(backup_csv_path)\n",
    "        \n",
    "    # Rate limiting: pause between requests to avoid hitting the rate limit\n",
    "    time.sleep(1)  \n",
    "    \n",
    "    return address_dict[query_key]\n",
    "\n",
    "# Execute method \n",
    "# housing_data_codeA[\"Latitude\"], housing_data_codeA[\"Longitude\"] = zip(*housing_data_codeA.apply(\n",
    "#     lambda row: getMeridian(row[\"Address\"], row[\"Zip_Code\"], row[\"Borough\"], row.name), axis=1))\n",
    "\n",
    "# housing_data_codeA.to_csv(final_csv_path, index=False)\n",
    "# print(f\"Completed! The final data has been saved to data folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc14be",
   "metadata": {},
   "source": [
    "Create CSV file with nearest trainstation and its distance to each property included as columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a496277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to calculate closest train station to each property \n",
    "\n",
    "import numpy as np \n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "geo_codeA = pd.read_csv(\"/Users/atwoo/Documents/Fairly_even/data/geocoded_housing_data_codeA_final.csv\")\n",
    "geo_codeA.dropna(axis= 0, subset= [\"Latitude\", \"Longitude\"], inplace= True)\n",
    "geo_codeA = geo_codeA.reset_index()\n",
    "station_data = pd.read_csv(\"/Users/atwoo/Documents/Fairly_even/data/clean_station_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "def calculate_distance (latitude_1: float, longitude_1: float, latitude_2: float, longitude_2: float) -> float:\n",
    "    \"\"\"Calculate the distance in meters between two latitude and longitude coordinate points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude_1 : float\n",
    "        latitude value of first coordinate point\n",
    "    longitude_1 : float\n",
    "        longitude value of first coordinate point\n",
    "    latitude_2 : float\n",
    "        latitude value of second coordinate point\n",
    "    longitude_2 : float\n",
    "        longitude value of second coordinate point\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        distance between coordinate points \n",
    "    \"\"\"\n",
    "\n",
    "    return geodesic((latitude_1, longitude_1), (latitude_2, longitude_2)).meters\n",
    "\n",
    "def get_nearest_station (property_latitude: float, property_longitude: float, station_df) -> tuple:\n",
    "    \"\"\"Find the nearest train station name and its distance to the inputted property's latitude and longitude coordinate points\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    property_latitude : float\n",
    "        latitude value of the property \n",
    "    property_longitude : float\n",
    "        longitude value of the property        \n",
    "    station_df : csv file \n",
    "        Csv file containing the station data for all train stations in new york. Each row must have a two columns correpsonding to a stations latitude and longitude, \n",
    "        titled Station_Latitude and Station_Longitude respectively.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        returns tuple of station name followed by distance of station to property\n",
    "\n",
    "    \"\"\"\n",
    "    distances = station_df.apply(lambda row: calculate_distance(property_latitude, property_longitude, row[\"Station_Latitude\"], row[\"Station_Longitude\"]), axis=1)\n",
    "    dist_idx = distances.idxmin()\n",
    "    nearest_station = station_df.loc[dist_idx, \"Stop Name\"]\n",
    "    nearest_station_dist = distances.min()\n",
    "\n",
    "    return nearest_station, nearest_station_dist\n",
    "\n",
    "\n",
    "# geo_codeA[[\"Nearest_Station\", \"Station_Distance\"]] = geo_codeA.apply(lambda row: pd.Series(get_nearest_station(row[\"Latitude\"], row[\"Longitude\"], station_data)), axis=1)\n",
    "geo_codeA = geo_codeA.drop(columns=[\"index\"])\n",
    "\n",
    "# file_name = \"combined_station_geocode.csv\"\n",
    "# save_path = os.path.join(\"/Users/atwoo/Documents/Fairly_even/data\",file_name)\n",
    "# geo_codeA.to_csv(save_path)\n",
    "# print(\"CSV file created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9068c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"/Users/atwoo/Documents/Fairly_even/data/combined_station_geocode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32b14f89-c746-481f-a4da-9cec85e450f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Borough', 'Neighborhood',\n",
       "       'Building_Class_Category',\n",
       "       'Building_Classification_Code_At_Time_Of_Sale', 'Address', 'Zip_Code',\n",
       "       'Sale_Price', 'Sale_Date', 'Year', 'Latitude', 'Longitude',\n",
       "       'Nearest_Station', 'Station_Distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "650f8c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate lag and price change\n",
    "def calculate_price_changes(group):\n",
    "    # Sort the group by Year\n",
    "    group = group.sort_values(by=\"Year\")\n",
    "    \n",
    "    # Create an empty list to store the changes\n",
    "    changes = []\n",
    "    \n",
    "    # Loop over all possible pairs of years in the group\n",
    "    for i in range(len(group)):\n",
    "        for j in range(i + 1, len(group)):\n",
    "            year_diff = group.iloc[j]['Year'] - group.iloc[i]['Year']\n",
    "            price_change = group.iloc[j]['Sale_Price'] - group.iloc[i]['Sale_Price']\n",
    "            \n",
    "            # Create a new column name based on the year difference\n",
    "            col_name = f\"Price_Change_{year_diff}_Years\"\n",
    "            group.loc[group.index[j], col_name] = price_change\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group of properties\n",
    "df_result = combined_df.groupby(\"Address\").apply(calculate_price_changes)\n",
    "\n",
    "df_result = df_result.reset_index(drop=True)\n",
    "\n",
    "print(\"DONE!\")\n",
    "#Re-order the columns in order of year increasing\n",
    "price_idx = [\"Price_Change_0_Years\",\"Price_Change_1_Years\",\"Price_Change_2_Years\",\"Price_Change_3_Years\",\"Price_Change_4_Years\",\"Price_Change_5_Years\",\"Price_Change_6_Years\",\"Price_Change_7_Years\",\"Price_Change_8_Years\",\"Price_Change_9_Years\",\"Price_Change_10_Years\",\"Price_Change_11_Years\",\"Price_Change_12_Years\"]\n",
    "reordered_cols = df_result[price_idx]\n",
    "remaining_cols = df_result.drop(columns=price_idx)\n",
    "df_result = pd.concat([remaining_cols, reordered_cols], axis=1)\n",
    "df_result = df_result.drop(columns= ['Unnamed: 0', 'index'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318828b5",
   "metadata": {},
   "source": [
    "The code below is a sanity check to see how many lag features have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "58ed4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with a value for the specified classification codes in column Price_Change_0_Years is: 1452\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_1_Years is: 1841\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_2_Years is: 1287\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_3_Years is: 1048\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_4_Years is: 971\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_5_Years is: 845\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_6_Years is: 704\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_7_Years is: 615\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_8_Years is: 554\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_9_Years is: 530\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_10_Years is: 419\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_11_Years is: 261\n",
      "Number of rows with a value for the specified classification codes in column Price_Change_12_Years is: 117\n"
     ]
    }
   ],
   "source": [
    "# Define the classification codes of interest\n",
    "classification_codes = [\"A5\"]\n",
    "\n",
    "# Initialize a dictionary to store the counts for each price change column\n",
    "counts = {}\n",
    "\n",
    "# Iterate over each years_ahead lag feature\n",
    "for i in range(13):\n",
    "    feature_col = f'Price_Change_{i}_Years'\n",
    "    \n",
    "    # Filter the DataFrame for rows with the desired classification codes and non-null values in the feature column\n",
    "    filtered_df = df_result[\n",
    "        (df_result[\"Building_Classification_Code_At_Time_Of_Sale\"].isin(classification_codes)) & (df_result[feature_col].notna())]\n",
    "    \n",
    "    # Store the count of rows that meet the criteria\n",
    "    counts[feature_col] = len(filtered_df)\n",
    "\n",
    "# Print the results\n",
    "for feature_col, count in counts.items():\n",
    "    print(f\"Number of rows with a value for the specified classification codes in column {feature_col} is: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9a2db4b7-e951-4181-8a04-1fddb4bfdf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 0 has 3032 negative values\n",
      "year 1 has 1440 negative values\n",
      "year 2 has 1178 negative values\n",
      "year 3 has 1194 negative values\n",
      "year 4 has 1190 negative values\n",
      "year 5 has 1053 negative values\n",
      "year 6 has 892 negative values\n",
      "year 7 has 858 negative values\n",
      "year 8 has 720 negative values\n",
      "year 9 has 528 negative values\n",
      "year 10 has 323 negative values\n",
      "year 11 has 105 negative values\n",
      "year 12 has 38 negative values\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    n_col = f'Price_Change_{i}_Years'\n",
    "    print(f\"year {i} has {(df_result[n_col] < 0).sum()} negative values\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a9ee3f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Building_Classification_Code_At_Time_Of_Sale\n",
       "A0      500\n",
       "A1    16626\n",
       "A2     6228\n",
       "A3      651\n",
       "A4      760\n",
       "A5    15264\n",
       "A6      334\n",
       "A7       20\n",
       "A8        2\n",
       "A9     3867\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows for each building classification code\n",
    "building_code_counts = df_result.groupby('Building_Classification_Code_At_Time_Of_Sale').size()\n",
    "building_code_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb24506",
   "metadata": {},
   "source": [
    "It appears that the majority of the buildings in the One Family Dwellings Building category fall under the classification codes of:\n",
    "- A1: TWO STORIES - DETACHED SM OR MID\n",
    "- A2: ONE STORY - PERMANENT LIVING QUARTER\n",
    "- A5: ONE FAMILY ATTACHED OR SEMI-DETACHED\n",
    "- A9: MISCELLANEOUS ONE FAMILY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b580f-edee-49c7-a618-d5115f8f0b47",
   "metadata": {},
   "source": [
    "MODIFY CELL BLOCK BELOW distance is in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fe602c1-0af1-4a3e-bef9-e7fd56ce1563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0 - 531.0        8846\n",
       "531.0 - 1092.0     8858\n",
       "1092.0 - 1861.0    8845\n",
       "1861.0 - 3357.0    8851\n",
       "3357.0 - 8763.0    8852\n",
       "Name: Station_Distance_Group, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def categorize_station_distance(df, num_groups=3):\n",
    "    # Create quantile-based bins\n",
    "    bins = pd.qcut(df['Station_Distance'], num_groups, retbins=True, duplicates='drop')[1]\n",
    "    \n",
    "    # Round bins to the nearest whole number\n",
    "    rounded_bins = np.round(bins)\n",
    "    \n",
    "    rounded_bins = np.unique(rounded_bins)  \n",
    "\n",
    "    # Define labels as interval ranges\n",
    "    interval_labels = [f'{rounded_bins[i]} - {rounded_bins[i+1]}' for i in range(len(rounded_bins) - 1)]\n",
    "    \n",
    "    # Create a new column in the DataFrame with the interval labels\n",
    "    df['Station_Distance_Group'] = pd.cut(df['Station_Distance'], bins=rounded_bins, labels=interval_labels, include_lowest=True)\n",
    "    \n",
    "    return df\n",
    "df_result = categorize_station_distance(df_result, 5)\n",
    "group_counts = df_result['Station_Distance_Group'].value_counts().sort_index()\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b1a6be02-df85-40bf-a894-beb1d87e90df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Staten, A1 0 years ahead was saved.\n",
      "Model for Staten, A1 1 years ahead was saved.\n",
      "Model for Staten, A1 2 years ahead was saved.\n",
      "Model for Staten, A1 3 years ahead was saved.\n",
      "Model for Staten, A1 4 years ahead was saved.\n",
      "Model for Staten, A1 5 years ahead was saved.\n",
      "Model for Staten, A5 0 years ahead was saved.\n",
      "Model for Staten, A5 1 years ahead was saved.\n",
      "Model for Staten, A5 2 years ahead was saved.\n",
      "Model for Staten, A5 3 years ahead was saved.\n",
      "Model for Staten, A5 4 years ahead was saved.\n",
      "Model for Staten, A5 5 years ahead was saved.\n",
      "Model for Staten, A2 0 years ahead was saved.\n",
      "Model for Staten, A2 1 years ahead was saved.\n",
      "Model for Staten, A2 2 years ahead was saved.\n",
      "Model for Staten, A2 3 years ahead was saved.\n",
      "Model for Staten, A2 4 years ahead was saved.\n",
      "Model for Staten, A2 5 years ahead was saved.\n",
      "Model for Queens, A1 0 years ahead was saved.\n",
      "Model for Queens, A1 1 years ahead was saved.\n",
      "Model for Queens, A1 2 years ahead was saved.\n",
      "Model for Queens, A1 3 years ahead was saved.\n",
      "Model for Queens, A1 4 years ahead was saved.\n",
      "Model for Queens, A1 5 years ahead was saved.\n",
      "Model for Queens, A5 0 years ahead was saved.\n",
      "Model for Queens, A5 1 years ahead was saved.\n",
      "Model for Queens, A5 2 years ahead was saved.\n",
      "Model for Queens, A5 3 years ahead was saved.\n",
      "Model for Queens, A5 4 years ahead was saved.\n",
      "Model for Queens, A5 5 years ahead was saved.\n",
      "Model for Queens, A2 0 years ahead was saved.\n",
      "Model for Queens, A2 1 years ahead was saved.\n",
      "Model for Queens, A2 2 years ahead was saved.\n",
      "Model for Queens, A2 3 years ahead was saved.\n",
      "Model for Queens, A2 4 years ahead was saved.\n",
      "Model for Queens, A2 5 years ahead was saved.\n",
      "Model for Bronx, A1 0 years ahead was saved.\n",
      "Model for Bronx, A1 1 years ahead was saved.\n",
      "Model for Bronx, A1 2 years ahead was saved.\n",
      "Model for Bronx, A1 3 years ahead was saved.\n",
      "Model for Bronx, A1 4 years ahead was saved.\n",
      "Model for Bronx, A1 5 years ahead was saved.\n",
      "Model for Bronx, A5 0 years ahead was saved.\n",
      "Model for Bronx, A5 1 years ahead was saved.\n",
      "Model for Bronx, A5 2 years ahead was saved.\n",
      "Model for Bronx, A5 3 years ahead was saved.\n",
      "Model for Bronx, A5 4 years ahead was saved.\n",
      "Model for Bronx, A5 5 years ahead was saved.\n",
      "Model for Bronx, A2 0 years ahead was saved.\n",
      "Model for Bronx, A2 1 years ahead was saved.\n",
      "Model for Bronx, A2 2 years ahead was saved.\n",
      "Model for Bronx, A2 3 years ahead was saved.\n",
      "Model for Bronx, A2 4 years ahead was saved.\n",
      "Model for Bronx, A2 5 years ahead was saved.\n",
      "Model for Brooklyn, A1 0 years ahead was saved.\n",
      "Model for Brooklyn, A1 1 years ahead was saved.\n",
      "Model for Brooklyn, A1 2 years ahead was saved.\n",
      "Model for Brooklyn, A1 3 years ahead was saved.\n",
      "Model for Brooklyn, A1 4 years ahead was saved.\n",
      "Model for Brooklyn, A1 5 years ahead was saved.\n",
      "Model for Brooklyn, A5 0 years ahead was saved.\n",
      "Model for Brooklyn, A5 1 years ahead was saved.\n",
      "Model for Brooklyn, A5 2 years ahead was saved.\n",
      "Model for Brooklyn, A5 3 years ahead was saved.\n",
      "Model for Brooklyn, A5 4 years ahead was saved.\n",
      "Model for Brooklyn, A5 5 years ahead was saved.\n",
      "Model for Brooklyn, A2 0 years ahead was saved.\n",
      "Model for Brooklyn, A2 1 years ahead was saved.\n",
      "Model for Brooklyn, A2 2 years ahead was saved.\n",
      "Model for Brooklyn, A2 3 years ahead was saved.\n",
      "Model for Brooklyn, A2 4 years ahead was saved.\n",
      "Model for Brooklyn, A2 5 years ahead was saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data\"\n",
    "file_name = \"final_df.csv\"\n",
    "data_path = os.path.join(folder_directory, file_name)\n",
    "\n",
    "df_result = pd.read_csv(data_path)\n",
    "\n",
    "# List of popular building classification codes\n",
    "popular_codes = ['A1', 'A5', 'A2']  # Replace with actual codes\n",
    "\n",
    "# List of boroughs\n",
    "boroughs = [\"Staten\", \"Queens\", \"Bronx\", \"Brooklyn\"]\n",
    "\n",
    "for i in range(13):\n",
    "    n_col = f'Price_Change_{i}_Years'\n",
    "    df_result[n_col] = df_result[n_col].apply(lambda x: 0 if x < 0 else x) \n",
    "\n",
    "\n",
    "# Iterate over each borough, building classification code, and years_ahead lag feature\n",
    "for borough in boroughs:\n",
    "    for building_code in popular_codes:\n",
    "        for i in range(6):\n",
    "            feature_col = f'Price_Change_{i}_Years'\n",
    "            \n",
    "            # Drop rows where price change column i year's value is NaN indicating that the dropped row didnt \n",
    "            # have a price change value for the desired i years ahead \n",
    "        \n",
    "            df_nonan = df_result.dropna(subset=[feature_col])\n",
    "            df_filtered = df_nonan[ (df_nonan['Building_Classification_Code_At_Time_Of_Sale'] == building_code) & \n",
    "                                        (df_nonan['Borough'] == borough)]\n",
    "\n",
    "            # Define X (features) and y (target)\n",
    "            numerical_features = df_filtered[['Sale_Price', 'Station_Distance']]\n",
    "\n",
    "            # Combine numerical and categorical features\n",
    "            features = numerical_features\n",
    "\n",
    "            # Target variable is the values in price change i years column\n",
    "            target = df_filtered[feature_col]  \n",
    "\n",
    "            # Ensure features and target have no missing values\n",
    "            features = features.dropna()\n",
    "            target = target.loc[features.index]\n",
    "\n",
    "            # Check if data is available after processing\n",
    "            if features.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            # Train-test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=23)\n",
    "\n",
    "            # Initialize and train the model\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Save the model with borough, building_code, and years_ahead in the filename\n",
    "            model_filename = f'model_{borough}_{building_code}_years_ahead_{i}.pkl'\n",
    "            model_dir = \"/Users/atwoo/Documents/Fairly_even/models\"\n",
    "            model_filepath = os.path.join(model_dir, model_filename)\n",
    "            joblib.dump(model, model_filepath)\n",
    "\n",
    "            print(f\"Model for {borough}, {building_code} {i} years ahead was saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e490bf81-943b-407d-8ce5-21d7a6935d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted property value in 5 years is: 400661.57\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def predict_property_value(current_property_value, years_ahead, building_code, borough, station_distance):\n",
    "    # Validate the years_ahead parameter\n",
    "    if years_ahead < 0 or years_ahead > 5:\n",
    "        raise ValueError(\"Years ahead must be between 0 and 5.\")\n",
    "\n",
    "    # Load the corresponding model based on borough, building code, and years ahead\n",
    "    model_filename = f'model_{borough}_{building_code}_years_ahead_{years_ahead}.pkl'\n",
    "    model_path = os.path.join(\"/Users/atwoo/Documents/Fairly_even/models\", model_filename)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"The model for {borough}, {building_code}, {years_ahead} years ahead does not exist.\")\n",
    "    \n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    # Prepare the input data\n",
    "    input_data = pd.DataFrame({\n",
    "        'Sale_Price': [current_property_value],\n",
    "        'Station_Distance': [station_distance],\n",
    "    })\n",
    "\n",
    "    # # Convert categorical variables to dummies to match the model's feature set\n",
    "    # input_data = pd.get_dummies(input_data, drop_first=True)\n",
    "    \n",
    "    # # Ensure the input_data matches the model's feature set\n",
    "    # model_features = model.feature_names_in_\n",
    "    # missing_features = set(model_features) - set(input_data.columns)\n",
    "    \n",
    "    # # Add missing columns to input_data with zeros\n",
    "    # for feature in missing_features:\n",
    "    #     input_data[feature] = 0\n",
    "\n",
    "    # # Reorder columns to match the model's expected input\n",
    "    # input_data = input_data[model_features]\n",
    "    \n",
    "    # Make the prediction using the loaded model\n",
    "    predicted_price_change = model.predict(input_data)[0]\n",
    "    \n",
    "    # Calculate the predicted future property value\n",
    "    future_property_value = current_property_value + predicted_price_change\n",
    "    \n",
    "    return future_property_value\n",
    "\n",
    "# Example usage:\n",
    "current_value = 300000  # Current property value input by the user\n",
    "years_ahead = 5 # How many years ahead the user wants to predict\n",
    "building_code = \"A1\"     # Building classification code\n",
    "borough = \"Queens\"      # The borough the property is in\n",
    "station_distance = 500   # Distance of the property from the station in meters\n",
    "\n",
    "predicted_value = predict_property_value(current_value, years_ahead, building_code, borough, station_distance)\n",
    "print(f\"The predicted property value in {years_ahead} years is: {predicted_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4a353-ab52-4ccd-9201-c03285e57c69",
   "metadata": {},
   "source": [
    "Points to add to summary:\n",
    "\n",
    "Addition of for loop that makes price change values in each of the price change columns 0 if they are less than zero  \n",
    "- The purpose of this for loop is to ensure a prediction value that is greater than the property value inputted by the user because the purpose of this project is to predict property appreciation. Also due to the limitations of our data as the year increases the less sale price data is available thus, having negative values will incorrectly show price depreciation of property values.\n",
    "- In addition, again because of the lack of sale data, resulting in the lack of price change for year x data. I will limit the model to only predicting price change for 5 years in advance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a33a97b6-c34b-4e36-b089-cbee85f58a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for Staten, A1, 0 years ahead: 347\n",
      "Number of samples for Staten, A1, 1 years ahead: 655\n",
      "Number of samples for Staten, A1, 2 years ahead: 447\n",
      "Number of samples for Staten, A1, 3 years ahead: 345\n",
      "Number of samples for Staten, A1, 4 years ahead: 298\n",
      "Number of samples for Staten, A1, 5 years ahead: 245\n",
      "Number of samples for Staten, A1, 6 years ahead: 220\n",
      "Number of samples for Staten, A1, 7 years ahead: 203\n",
      "Number of samples for Staten, A1, 8 years ahead: 185\n",
      "Number of samples for Staten, A1, 9 years ahead: 163\n",
      "Number of samples for Staten, A1, 10 years ahead: 143\n",
      "Number of samples for Staten, A1, 11 years ahead: 76\n",
      "Number of samples for Staten, A1, 12 years ahead: 40\n",
      "Number of samples for Staten, A2, 0 years ahead: 148\n",
      "Number of samples for Staten, A2, 1 years ahead: 278\n",
      "Number of samples for Staten, A2, 2 years ahead: 180\n",
      "Number of samples for Staten, A2, 3 years ahead: 139\n",
      "Number of samples for Staten, A2, 4 years ahead: 115\n",
      "Number of samples for Staten, A2, 5 years ahead: 115\n",
      "Number of samples for Staten, A2, 6 years ahead: 94\n",
      "Number of samples for Staten, A2, 7 years ahead: 83\n",
      "Number of samples for Staten, A2, 8 years ahead: 76\n",
      "Number of samples for Staten, A2, 9 years ahead: 67\n",
      "Number of samples for Staten, A2, 10 years ahead: 54\n",
      "Number of samples for Staten, A2, 11 years ahead: 33\n",
      "Number of samples for Staten, A2, 12 years ahead: 12\n",
      "Number of samples for Staten, A5, 0 years ahead: 559\n",
      "Number of samples for Staten, A5, 1 years ahead: 681\n",
      "Number of samples for Staten, A5, 2 years ahead: 618\n",
      "Number of samples for Staten, A5, 3 years ahead: 565\n",
      "Number of samples for Staten, A5, 4 years ahead: 535\n",
      "Number of samples for Staten, A5, 5 years ahead: 473\n",
      "Number of samples for Staten, A5, 6 years ahead: 402\n",
      "Number of samples for Staten, A5, 7 years ahead: 337\n",
      "Number of samples for Staten, A5, 8 years ahead: 310\n",
      "Number of samples for Staten, A5, 9 years ahead: 336\n",
      "Number of samples for Staten, A5, 10 years ahead: 272\n",
      "Number of samples for Staten, A5, 11 years ahead: 187\n",
      "Number of samples for Staten, A5, 12 years ahead: 86\n",
      "Number of samples for Bronx, A1, 0 years ahead: 201\n",
      "Number of samples for Bronx, A1, 1 years ahead: 293\n",
      "Number of samples for Bronx, A1, 2 years ahead: 136\n",
      "Number of samples for Bronx, A1, 3 years ahead: 108\n",
      "Number of samples for Bronx, A1, 4 years ahead: 93\n",
      "Number of samples for Bronx, A1, 5 years ahead: 74\n",
      "Number of samples for Bronx, A1, 6 years ahead: 69\n",
      "Number of samples for Bronx, A1, 7 years ahead: 81\n",
      "Number of samples for Bronx, A1, 8 years ahead: 57\n",
      "Number of samples for Bronx, A1, 9 years ahead: 45\n",
      "Number of samples for Bronx, A1, 10 years ahead: 46\n",
      "Number of samples for Bronx, A1, 11 years ahead: 21\n",
      "Number of samples for Bronx, A1, 12 years ahead: 12\n",
      "Number of samples for Bronx, A2, 0 years ahead: 66\n",
      "Number of samples for Bronx, A2, 1 years ahead: 96\n",
      "Number of samples for Bronx, A2, 2 years ahead: 69\n",
      "Number of samples for Bronx, A2, 3 years ahead: 40\n",
      "Number of samples for Bronx, A2, 4 years ahead: 26\n",
      "Number of samples for Bronx, A2, 5 years ahead: 26\n",
      "Number of samples for Bronx, A2, 6 years ahead: 24\n",
      "Number of samples for Bronx, A2, 7 years ahead: 23\n",
      "Number of samples for Bronx, A2, 8 years ahead: 20\n",
      "Number of samples for Bronx, A2, 9 years ahead: 18\n",
      "Number of samples for Bronx, A2, 10 years ahead: 11\n",
      "Number of samples for Bronx, A2, 11 years ahead: 13\n",
      "Number of samples for Bronx, A2, 12 years ahead: 6\n",
      "Number of samples for Bronx, A5, 0 years ahead: 200\n",
      "Number of samples for Bronx, A5, 1 years ahead: 244\n",
      "Number of samples for Bronx, A5, 2 years ahead: 156\n",
      "Number of samples for Bronx, A5, 3 years ahead: 102\n",
      "Number of samples for Bronx, A5, 4 years ahead: 122\n",
      "Number of samples for Bronx, A5, 5 years ahead: 66\n",
      "Number of samples for Bronx, A5, 6 years ahead: 46\n",
      "Number of samples for Bronx, A5, 7 years ahead: 62\n",
      "Number of samples for Bronx, A5, 8 years ahead: 57\n",
      "Number of samples for Bronx, A5, 9 years ahead: 30\n",
      "Number of samples for Bronx, A5, 10 years ahead: 45\n",
      "Number of samples for Bronx, A5, 11 years ahead: 24\n",
      "Number of samples for Bronx, A5, 12 years ahead: 15\n",
      "Number of samples for Queens, A1, 0 years ahead: 1019\n",
      "Number of samples for Queens, A1, 1 years ahead: 1432\n",
      "Number of samples for Queens, A1, 2 years ahead: 693\n",
      "Number of samples for Queens, A1, 3 years ahead: 549\n",
      "Number of samples for Queens, A1, 4 years ahead: 442\n",
      "Number of samples for Queens, A1, 5 years ahead: 351\n",
      "Number of samples for Queens, A1, 6 years ahead: 269\n",
      "Number of samples for Queens, A1, 7 years ahead: 247\n",
      "Number of samples for Queens, A1, 8 years ahead: 206\n",
      "Number of samples for Queens, A1, 9 years ahead: 104\n",
      "Number of samples for Queens, A1, 10 years ahead: 71\n",
      "Number of samples for Queens, A1, 11 years ahead: 27\n",
      "Number of samples for Queens, A1, 12 years ahead: 0\n",
      "Number of samples for Queens, A2, 0 years ahead: 303\n",
      "Number of samples for Queens, A2, 1 years ahead: 428\n",
      "Number of samples for Queens, A2, 2 years ahead: 174\n",
      "Number of samples for Queens, A2, 3 years ahead: 119\n",
      "Number of samples for Queens, A2, 4 years ahead: 109\n",
      "Number of samples for Queens, A2, 5 years ahead: 73\n",
      "Number of samples for Queens, A2, 6 years ahead: 84\n",
      "Number of samples for Queens, A2, 7 years ahead: 73\n",
      "Number of samples for Queens, A2, 8 years ahead: 34\n",
      "Number of samples for Queens, A2, 9 years ahead: 40\n",
      "Number of samples for Queens, A2, 10 years ahead: 21\n",
      "Number of samples for Queens, A2, 11 years ahead: 6\n",
      "Number of samples for Queens, A2, 12 years ahead: 1\n",
      "Number of samples for Queens, A5, 0 years ahead: 422\n",
      "Number of samples for Queens, A5, 1 years ahead: 538\n",
      "Number of samples for Queens, A5, 2 years ahead: 306\n",
      "Number of samples for Queens, A5, 3 years ahead: 233\n",
      "Number of samples for Queens, A5, 4 years ahead: 172\n",
      "Number of samples for Queens, A5, 5 years ahead: 176\n",
      "Number of samples for Queens, A5, 6 years ahead: 139\n",
      "Number of samples for Queens, A5, 7 years ahead: 110\n",
      "Number of samples for Queens, A5, 8 years ahead: 100\n",
      "Number of samples for Queens, A5, 9 years ahead: 81\n",
      "Number of samples for Queens, A5, 10 years ahead: 46\n",
      "Number of samples for Queens, A5, 11 years ahead: 11\n",
      "Number of samples for Queens, A5, 12 years ahead: 4\n",
      "Number of samples for Brooklyn, A1, 0 years ahead: 199\n",
      "Number of samples for Brooklyn, A1, 1 years ahead: 285\n",
      "Number of samples for Brooklyn, A1, 2 years ahead: 156\n",
      "Number of samples for Brooklyn, A1, 3 years ahead: 133\n",
      "Number of samples for Brooklyn, A1, 4 years ahead: 126\n",
      "Number of samples for Brooklyn, A1, 5 years ahead: 96\n",
      "Number of samples for Brooklyn, A1, 6 years ahead: 75\n",
      "Number of samples for Brooklyn, A1, 7 years ahead: 70\n",
      "Number of samples for Brooklyn, A1, 8 years ahead: 69\n",
      "Number of samples for Brooklyn, A1, 9 years ahead: 69\n",
      "Number of samples for Brooklyn, A1, 10 years ahead: 41\n",
      "Number of samples for Brooklyn, A1, 11 years ahead: 27\n",
      "Number of samples for Brooklyn, A1, 12 years ahead: 10\n",
      "Number of samples for Brooklyn, A2, 0 years ahead: 68\n",
      "Number of samples for Brooklyn, A2, 1 years ahead: 95\n",
      "Number of samples for Brooklyn, A2, 2 years ahead: 59\n",
      "Number of samples for Brooklyn, A2, 3 years ahead: 43\n",
      "Number of samples for Brooklyn, A2, 4 years ahead: 28\n",
      "Number of samples for Brooklyn, A2, 5 years ahead: 29\n",
      "Number of samples for Brooklyn, A2, 6 years ahead: 18\n",
      "Number of samples for Brooklyn, A2, 7 years ahead: 19\n",
      "Number of samples for Brooklyn, A2, 8 years ahead: 15\n",
      "Number of samples for Brooklyn, A2, 9 years ahead: 19\n",
      "Number of samples for Brooklyn, A2, 10 years ahead: 20\n",
      "Number of samples for Brooklyn, A2, 11 years ahead: 8\n",
      "Number of samples for Brooklyn, A2, 12 years ahead: 3\n",
      "Number of samples for Brooklyn, A5, 0 years ahead: 270\n",
      "Number of samples for Brooklyn, A5, 1 years ahead: 378\n",
      "Number of samples for Brooklyn, A5, 2 years ahead: 204\n",
      "Number of samples for Brooklyn, A5, 3 years ahead: 146\n",
      "Number of samples for Brooklyn, A5, 4 years ahead: 140\n",
      "Number of samples for Brooklyn, A5, 5 years ahead: 130\n",
      "Number of samples for Brooklyn, A5, 6 years ahead: 116\n",
      "Number of samples for Brooklyn, A5, 7 years ahead: 106\n",
      "Number of samples for Brooklyn, A5, 8 years ahead: 87\n",
      "Number of samples for Brooklyn, A5, 9 years ahead: 82\n",
      "Number of samples for Brooklyn, A5, 10 years ahead: 56\n",
      "Number of samples for Brooklyn, A5, 11 years ahead: 39\n",
      "Number of samples for Brooklyn, A5, 12 years ahead: 12\n",
      "Number of samples for Manhattan, A1, 0 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 1 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 2 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 3 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 4 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 5 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 6 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 7 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 8 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 9 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 10 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 11 years ahead: 0\n",
      "Number of samples for Manhattan, A1, 12 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 0 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 1 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 2 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 3 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 4 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 5 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 6 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 7 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 8 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 9 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 10 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 11 years ahead: 0\n",
      "Number of samples for Manhattan, A2, 12 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 0 years ahead: 1\n",
      "Number of samples for Manhattan, A5, 1 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 2 years ahead: 3\n",
      "Number of samples for Manhattan, A5, 3 years ahead: 2\n",
      "Number of samples for Manhattan, A5, 4 years ahead: 2\n",
      "Number of samples for Manhattan, A5, 5 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 6 years ahead: 1\n",
      "Number of samples for Manhattan, A5, 7 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 8 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 9 years ahead: 1\n",
      "Number of samples for Manhattan, A5, 10 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 11 years ahead: 0\n",
      "Number of samples for Manhattan, A5, 12 years ahead: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "folder_directory = \"/Users/atwoo/Documents/Fairly_even/data\"\n",
    "file_name = \"final_df.csv\"\n",
    "data_path = os.path.join(folder_directory, file_name)\n",
    "\n",
    "df_result = pd.read_csv(data_path)\n",
    "\n",
    "# List of popular building classification codes\n",
    "popular_codes = ['A1', 'A2', 'A5']  # Replace with actual codes\n",
    "\n",
    "# List of boroughs\n",
    "boroughs = df_result['Borough'].unique()\n",
    "\n",
    "# Iterate over each borough, building classification code, and years_ahead lag feature\n",
    "for borough in boroughs:\n",
    "    for building_code in popular_codes:\n",
    "        for i in range(13):\n",
    "            feature_col = f'Price_Change_{i}_Years'\n",
    "            \n",
    "            # Filter rows for the given borough and building code and where the feature is not NaN\n",
    "            df_nonan = df_result.dropna(subset=[feature_col])\n",
    "            df_filtered = df_nonan[\n",
    "                (df_nonan['Building_Classification_Code_At_Time_Of_Sale'] == building_code) &\n",
    "                (df_nonan['Borough'] == borough)\n",
    "            ]\n",
    "\n",
    "            # Define X (features) and y (target)\n",
    "            numerical_features = df_filtered[['Sale_Price', 'Station_Distance']]  # Include numeric variables\n",
    "\n",
    "            # Combine numerical and categorical features\n",
    "            features = numerical_features\n",
    "\n",
    "            # Target variable\n",
    "            target = df_filtered[feature_col]  # Target is the price change\n",
    "\n",
    "            # Ensure features and target have no missing values\n",
    "            features = features.dropna()\n",
    "            target = target.loc[features.index]\n",
    "\n",
    "            # Print the number of samples\n",
    "            num_samples = len(features)\n",
    "            print(f\"Number of samples for {borough}, {building_code}, {i} years ahead: {num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3bb9e0-fdf5-4fd1-b215-50812ef19b45",
   "metadata": {},
   "source": [
    "Code to see the number of features created for each potential model \n",
    "- As you can see Manhattan has little to no data for these specific house building codes and after about year 5 the majority of feature columns is only double digit for most boroughs.\n",
    "- Therefore, I will create models for all boroughs except Manhattan and only predict at most 5 years ahead for each borough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972523a-bd32-408c-8aa1-9bee46a1d92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
